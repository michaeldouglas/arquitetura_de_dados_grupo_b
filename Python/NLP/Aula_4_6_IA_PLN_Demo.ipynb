{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghedin-alison/NLP/blob/main/Aula_4_6_IA_PLN_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ont8JX9spNZz"
      },
      "source": [
        "# **NLTK**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtRjU5tRYZQ3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import tokenize\n",
        "\n",
        "texto_exemplo = \"Não sei se entendi como ler o conteúdo da view, então. \\\n",
        "Estou entendendo que a view contém um histórico das movimentações \\\n",
        "dos associados, certo?\"\n",
        "\n",
        "# Exemplo tokenização\n",
        "tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReDnaw00nJid"
      },
      "source": [
        "Documentação nltk.tokenize: https://www.nltk.org/api/nltk.tokenize.html\n",
        "\n",
        "Exemplos em português: http://www.nltk.org/howto/portuguese_en.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPHAfEYkVp-f"
      },
      "source": [
        "POS-Tagger NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNORsKEaTbFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b14f114-e4d7-46d7-b5bb-00baae8753b3"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "pos_tag(word_tokenize('O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que', language=\"portuguese\"), tagset='universal')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'NOUN'),\n",
              " ('Hobbit', 'NOUN'),\n",
              " ('-', '.'),\n",
              " ('7ª', 'NUM'),\n",
              " ('Ed.', 'ADJ'),\n",
              " ('2013', 'NUM'),\n",
              " ('Produto', 'NOUN'),\n",
              " ('NovoBilbo', 'NOUN'),\n",
              " ('Bolseiro', 'NOUN'),\n",
              " ('é', 'NOUN'),\n",
              " ('um', 'ADJ'),\n",
              " ('hobbit', 'NOUN'),\n",
              " ('que', 'NOUN')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGbw2K4UTdon"
      },
      "source": [
        "# **Sobre o corpus Floresta**\n",
        "\n",
        "---\n",
        "Conhecido como \"Floresta Sintática\". Conjunto de frases já analisadas sintáticamente e tageadas.\n",
        "\n",
        "https://www.linguateca.pt/Floresta/\n",
        "\n",
        "https://www.linguateca.pt/floresta/doc/VISLsymbolset-manual.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kySnyrT1c1sy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb657a64-f126-41ff-a868-709d3432b280"
      },
      "source": [
        "from nltk.corpus import floresta\n",
        "import nltk\n",
        "nltk.download('floresta')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/floresta.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mE1kjHprAkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9696a6c-c914-44d0-d0f8-83420e16810f"
      },
      "source": [
        "print(nltk.corpus.floresta.readme())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portuguese Treebank\n",
            "\n",
            "Projecto Floresta Sinta(c)tica -- http://www.linguateca.pt/Floresta/\n",
            "Version 7.4  Distributed with permission.\n",
            "\n",
            "Penn Treebank format, available from http://linguateca.di.uminho.pt/FS/fs.html\n",
            "\n",
            "Key to tags (http://visl.sdu.dk/visl/pt/portsymbol.html)\n",
            "\n",
            "<ACC          direct object\n",
            "<ACC-PASS     passive use of pronoun 'se'\n",
            "<ADVS, <ADVO  adverbial argument\n",
            "<ADVL         adjunct adverbial\n",
            "<DAT          dative (indirect) object\n",
            "<FOC          focus marker (or right focus bracket)\n",
            "<OC           object complement\n",
            "<PASS         agent of passive\n",
            "<PIV          prepositional object\n",
            "<PRED         free (subject) predicative, right of main verb\n",
            "<SC           subject complement\n",
            "<SUBJ         subject\n",
            ">A            adverbial pre-adject (intensifier before adjective, adverb, pronoun or participle)\n",
            ">N            prenominal modifier\n",
            ">P            modifier of prepositional phrase (intensifier, operator or focus adverb)\n",
            ">S            modifier of clause (intensifier, operator or focus adverb)\n",
            "A<            adverbial post-adject (modifier or argument of adjective, adverb or participle)\n",
            "A<ADV         adverbial argument of attributive participle\n",
            "A<ADVL        adverbial adjunct of attributive participle\n",
            "A<PASS        agent of passive after attributive participle\n",
            "A<PIV         prepositional object of attributive participle\n",
            "A<SC          subject complement of attributive participle\n",
            "ACC>          accusative (direct) object\n",
            "ACC>-PASS     passive use of pronoun 'se'\n",
            "ACC>>         double-fronted accusative (direct) object before matrix verb\n",
            "ADVS>, ADVO>  adverbial argument\n",
            "ADVL          top node adverbial\n",
            "ADVL>         adjunct adverbial\n",
            "ADVL>A        adjunct adverbial before attributive participle\n",
            "ADVL>AS<      adjunct adverbial in averbal clause\n",
            "APP           identifying apposition\n",
            "AS<           clause body of averbal clause\n",
            "CO            co-ordinator\n",
            "COM           comparator (heading averbal clause)\n",
            "DAT>          dative (intransitive) object\n",
            "FAUX          finite auxiliary\n",
            "FMV           finite main verb\n",
            "FOC>          focus marker (or left focus bracket)\n",
            "IAUX          non-finite auxiliary\n",
            "IMV           non-finite main verb\n",
            "KOMP<         argument of comparative hook\n",
            "N<            postnominal modifier or argument\n",
            "N<PRED        postnominal (in-group) predicative (or non-identifying apposition)\n",
            "NPHR          top node noun phrase\n",
            "NUM<          second part of numeral chain\n",
            "OC>           object complement\n",
            "P<            argument of preposition\n",
            "PIV>          prepositional object\n",
            "PRD           predicator (heading averbal clause)\n",
            "PRED>         free (subject) predicative, left of main verb\n",
            "PREF          prefix (category being phased out)\n",
            "PRT-AUX<      auxiliary particle\n",
            "S<            statement predicative (sentence apposition)\n",
            "SC>           subject complement\n",
            "SUB           subordinator\n",
            "SUBJ>         subject\n",
            "SUBJ>>        double-fronted subject, with interfering matrix og quoting verb\n",
            "TOP           topic constituent\n",
            "VOK           vocative constituent\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqcDbl4mdodH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6b8295-c2ae-467e-83f8-492aead96e69"
      },
      "source": [
        "floresta.tagged_words()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Um', '>N+art'), ('revivalismo', 'H+n'), ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbMcbwmoMoPU"
      },
      "source": [
        "As tags consistem em algumas informações sintáticas, seguidas por um sinal de mais, seguido por uma tag convencional de POS Tag com a classificação morfológica. Vamos retirar o material antes do sinal de mais (+):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk7WlFDaHasW",
        "outputId": "00b99624-3892-46cc-d659-f74774b8938a"
      },
      "source": [
        "'+' in 'anderson dourado'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVsS_hn0j1O5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c161c282-d682-4a1e-b011-8118fe8c9cb3"
      },
      "source": [
        "'+' in 'anderson+dourado'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE63qXqoA5W"
      },
      "source": [
        "# Função para simplificar a tag\n",
        "def simplifica_tag(t):\n",
        "  if \"+\" in t:\n",
        "    return t.split(\"+\")[1]\n",
        "  return t"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2SbIXeNmJf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc9bb75-acca-4fbc-e128-88f30f51c2e8"
      },
      "source": [
        "# Exemplo 1\n",
        "tag_words = nltk.corpus.floresta.tagged_words() #type(twords)\n",
        "\n",
        "list_palavras = [] #type(list_palavras)\n",
        "tuple_dupla = () #type(tuple_dupla)\n",
        "\n",
        "for word, tag in tag_words:\n",
        "  tuple_dupla = (word.lower(), simplifica_tag(tag))\n",
        "  list_palavras.append(tuple_dupla)\n",
        "\n",
        "list_palavras[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('um', 'art'),\n",
              " ('revivalismo', 'n'),\n",
              " ('refrescante', 'adj'),\n",
              " ('o', 'art'),\n",
              " ('7_e_meio', 'prop'),\n",
              " ('é', 'v-fin'),\n",
              " ('um', 'art'),\n",
              " ('ex-libris', 'n'),\n",
              " ('de', 'prp'),\n",
              " ('a', 'art')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D8P4BWEdq45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254c3ae7-6500-4751-b179-f6c8918b0ab8"
      },
      "source": [
        "# Exemplo 2\n",
        "tag_words = nltk.corpus.floresta.tagged_words()\n",
        "tag_words\n",
        "\n",
        "tag_words = [(w.lower(),simplifica_tag(t)) for (w,t) in tag_words]\n",
        "\n",
        "tag_words[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('um', 'art'),\n",
              " ('revivalismo', 'n'),\n",
              " ('refrescante', 'adj'),\n",
              " ('o', 'art'),\n",
              " ('7_e_meio', 'prop'),\n",
              " ('é', 'v-fin'),\n",
              " ('um', 'art'),\n",
              " ('ex-libris', 'n'),\n",
              " ('de', 'prp'),\n",
              " ('a', 'art')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3cHfOheAZ2"
      },
      "source": [
        "Exemplo de texto anotado (tagueado) no corpus Floresta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1EuM1jg_-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f711e10c-8f97-4bb7-f600-7a80fffd1cd6"
      },
      "source": [
        "print(' '.join(word + '/' + tag for (word, tag) in tag_words[:10]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "um/art revivalismo/n refrescante/adj o/art 7_e_meio/prop é/v-fin um/art ex-libris/n de/prp a/art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFK5xNB9Pg3N"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQQzXZP5pQ1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac82d617-a9ac-4f85-a28e-f8b4ce97b40d"
      },
      "source": [
        "tag_sents = floresta.tagged_sents()\n",
        "tag_sents[:2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Um', '>N+art'), ('revivalismo', 'H+n'), ('refrescante', 'N<+adj')],\n",
              " [('O', '>N+art'),\n",
              "  ('7_e_Meio', 'H+prop'),\n",
              "  ('é', 'P+v-fin'),\n",
              "  ('um', '>N+art'),\n",
              "  ('ex-libris', 'H+n'),\n",
              "  ('de', 'H+prp'),\n",
              "  ('a', '>N+art'),\n",
              "  ('noite', 'H+n'),\n",
              "  ('algarvia', 'N<+adj'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCbf1QPT1InW"
      },
      "source": [
        "# Contagem das tags e mantendo a estruturas das sentenças do corpus floresta\n",
        "from nltk.corpus import floresta\n",
        "from collections import Counter\n",
        "\n",
        "def simplifica_tag(t):\n",
        "  if \"+\" in t:\n",
        "    return t.split(\"+\")[1]\n",
        "  return t \n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "tag_sents = floresta.tagged_sents()\n",
        "tag_new_sents = []\n",
        "for sent in tag_sents:\n",
        "  new_sent = []\n",
        "  for (w,t) in sent:\n",
        "    tag = simplifica_tag(t)\n",
        "    new_sent.append((w.lower(), tag))\n",
        "    counter[tag] += 1\n",
        "  tag_new_sents.append(new_sent)\n",
        "\n",
        "#tag_sents[0]\n",
        "#tag_new_sents[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNc4oyTTRzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b3fbfa-6337-4a6c-a381-06997336753f"
      },
      "source": [
        "#new_sent\n",
        "tag_new_sents[:2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('um', 'art'), ('revivalismo', 'n'), ('refrescante', 'adj')],\n",
              " [('o', 'art'),\n",
              "  ('7_e_meio', 'prop'),\n",
              "  ('é', 'v-fin'),\n",
              "  ('um', 'art'),\n",
              "  ('ex-libris', 'n'),\n",
              "  ('de', 'prp'),\n",
              "  ('a', 'art'),\n",
              "  ('noite', 'n'),\n",
              "  ('algarvia', 'adj'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNmXhgOw1t7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b83d45e-4a6d-423a-89e1-f92933c25366"
      },
      "source": [
        "counter.most_common(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('n', 40081), ('prp', 32442), ('art', 29360), ('v-fin', 15802), (',', 13444)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6mPWpv62Z0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481affcc-e335-4ae6-c95c-a12b8c1c3b9d"
      },
      "source": [
        "# % dos substantivos\n",
        "counter.get('n') / sum(counter.values())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18919339916545513"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQ87t8fgAzX"
      },
      "source": [
        "Verificamos que a tag mais comum é N. Essa será nossa referência a tag padrão (gold)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKnTSb5Z7uBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53abfac1-d94a-4c81-bdf6-b9ae660e402d"
      },
      "source": [
        "# Crianto uma tag default\n",
        "default_tagger = nltk.DefaultTagger('n')\n",
        "\n",
        "token_texto_exemplo = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
        "default_tagger.tag(token_texto_exemplo)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'n'),\n",
              " ('se', 'n'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'n'),\n",
              " ('ler', 'n'),\n",
              " ('o', 'n'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', 'n'),\n",
              " ('então', 'n'),\n",
              " ('.', 'n'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'n'),\n",
              " ('que', 'n'),\n",
              " ('a', 'n'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'n'),\n",
              " ('histórico', 'n'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'n'),\n",
              " ('associados', 'n'),\n",
              " (',', 'n'),\n",
              " ('certo', 'n'),\n",
              " ('?', 'n')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZf9bpKwACxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb0510f-6818-4b08-ad0d-bff6a57e849a"
      },
      "source": [
        "# Analisando com base na tag padrão (tag ouro/gold)\n",
        "tag_sents = tag_new_sents\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('n')\n",
        "print(default_tagger.evaluate(tag_sents))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-c5f7fc87cf10>:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(default_tagger.evaluate(tag_sents))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18919339916545513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Atenção a esse ponto para o trabalho!!!"
      ],
      "metadata": {
        "id": "7m9xBR1OenDL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er6gXU5IhTkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd580c1e-c9c2-4fc7-fed2-ca7d2398d3ec"
      },
      "source": [
        "tag_sents = tag_new_sents\n",
        "#type(tag_sents) #len(tag_sents)\n",
        "#tag_sents[len(tag_sents)-1] #tag_sents[-1]\n",
        "\n",
        "tag_sents_treino = tag_sents[1000:]\n",
        "tag_sents_teste = tag_sents[:1000]\n",
        "\n",
        "tagger0 = nltk.DefaultTagger('n')\n",
        "print(tagger0.evaluate(tag_sents_teste))\n",
        "\n",
        "tagger1 = nltk.UnigramTagger(tag_sents_treino, backoff=tagger0)\n",
        "print(tagger1.evaluate(tag_sents_teste))\n",
        "\n",
        "tagger2 = nltk.BigramTagger(tag_sents_treino, backoff=tagger1)\n",
        "print(tagger2.evaluate(tag_sents_teste))\n",
        "\n",
        "tagger3 = nltk.TrigramTagger(tag_sents_treino, backoff=tagger2)\n",
        "print(tagger3.evaluate(tag_sents_teste))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3bac651b799b>:9: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(tagger0.evaluate(tag_sents_teste))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17800040072129833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3bac651b799b>:12: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(tagger1.evaluate(tag_sents_teste))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8740532959326788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3bac651b799b>:15: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(tagger2.evaluate(tag_sents_teste))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8900420757363254\n",
            "0.8887998397114807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3bac651b799b>:18: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(tagger3.evaluate(tag_sents_teste))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4lHBKC9xUB"
      },
      "source": [
        "\n",
        "Documentação dos métodos tag:\n",
        "  - https://www.nltk.org/api/nltk.tag.html\n",
        "\n",
        "Nos baseamos no métodos da documentação abaixo:\n",
        "  - Capítulo 5 - N-Gram Tagging: http://www.nltk.org/book/ch05.html\n",
        "  - Exemplo em português: http://www.nltk.org/howto/portuguese_en.html\n",
        "  - Outros corpus tageados: https://www.nltk.org/book/ch02.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAe-S-errcNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea37a04b-114c-48ed-bca3-268535346660"
      },
      "source": [
        "#from sklearn.externals import joblib\n",
        "import joblib\n",
        "\n",
        "joblib.dump(tagger2, 'tagger.pkl')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quA-JTPNOzcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d6a3ee-7524-43ec-96df-e1d85cab3bbc"
      },
      "source": [
        "!ls -all -h"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 420K\n",
            "drwxr-xr-x 1 root root 4.0K Mar 13 00:51 .\n",
            "drwxr-xr-x 1 root root 4.0K Mar 13 00:10 ..\n",
            "drwxr-xr-x 4 root root 4.0K Mar  9 18:57 .config\n",
            "drwxr-xr-x 1 root root 4.0K Mar  9 18:58 sample_data\n",
            "-rw-r--r-- 1 root root 401K Mar 13 00:51 tagger.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVCddXw7sVsa"
      },
      "source": [
        "bla = joblib.load('tagger.pkl')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKiTgA9ysc0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1959502-ffd1-4032-c57f-a4d4460562a9"
      },
      "source": [
        "print(bla.evaluate(tag_sents_teste))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8900420757363254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6d87d4e3cbac>:1: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(bla.evaluate(tag_sents_teste))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmZdOuNCaV0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadc6088-8b5e-42be-d96f-50d7e1c14d3c"
      },
      "source": [
        "texto_exemplo\n",
        "twords = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
        "tagger2.tag(twords)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'v-fin'),\n",
              " ('se', 'pron-pers'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'adv'),\n",
              " ('ler', 'v-inf'),\n",
              " ('o', 'art'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', ','),\n",
              " ('então', 'adv'),\n",
              " ('.', '.'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'v-ger'),\n",
              " ('que', 'conj-s'),\n",
              " ('a', 'art'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'art'),\n",
              " ('histórico', 'adj'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'prop'),\n",
              " ('associados', 'n'),\n",
              " (',', ','),\n",
              " ('certo', 'adj'),\n",
              " ('?', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI-YYFYUjwIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7a0ea0-73ec-47bd-f68c-2a93cbb75142"
      },
      "source": [
        "#twords = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
        "tagger2.tag(twords)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'v-fin'),\n",
              " ('se', 'pron-pers'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'adv'),\n",
              " ('ler', 'v-inf'),\n",
              " ('o', 'art'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', ','),\n",
              " ('então', 'adv'),\n",
              " ('.', '.'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'v-ger'),\n",
              " ('que', 'conj-s'),\n",
              " ('a', 'art'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'art'),\n",
              " ('histórico', 'adj'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'prop'),\n",
              " ('associados', 'n'),\n",
              " (',', ','),\n",
              " ('certo', 'adj'),\n",
              " ('?', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iIx3MhZkl-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc4ff46-96b2-428c-e770-972f41d3f323"
      },
      "source": [
        "tagger1.tag(twords)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Não', 'n'),\n",
              " ('sei', 'v-fin'),\n",
              " ('se', 'pron-pers'),\n",
              " ('entendi', 'n'),\n",
              " ('como', 'adv'),\n",
              " ('ler', 'v-inf'),\n",
              " ('o', 'art'),\n",
              " ('conteúdo', 'n'),\n",
              " ('da', 'n'),\n",
              " ('view', 'n'),\n",
              " (',', ','),\n",
              " ('então', 'adv'),\n",
              " ('.', '.'),\n",
              " ('Estou', 'n'),\n",
              " ('entendendo', 'v-ger'),\n",
              " ('que', 'pron-indp'),\n",
              " ('a', 'art'),\n",
              " ('view', 'n'),\n",
              " ('contém', 'n'),\n",
              " ('um', 'art'),\n",
              " ('histórico', 'adj'),\n",
              " ('das', 'n'),\n",
              " ('movimentações', 'n'),\n",
              " ('dos', 'prop'),\n",
              " ('associados', 'n'),\n",
              " (',', ','),\n",
              " ('certo', 'adj'),\n",
              " ('?', '?')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inKncgHXouUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc29b4d-a88a-48e3-a646-de0d0719fa4c"
      },
      "source": [
        "print(nltk.corpus.floresta.readme()[:1000])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portuguese Treebank\n",
            "\n",
            "Projecto Floresta Sinta(c)tica -- http://www.linguateca.pt/Floresta/\n",
            "Version 7.4  Distributed with permission.\n",
            "\n",
            "Penn Treebank format, available from http://linguateca.di.uminho.pt/FS/fs.html\n",
            "\n",
            "Key to tags (http://visl.sdu.dk/visl/pt/portsymbol.html)\n",
            "\n",
            "<ACC          direct object\n",
            "<ACC-PASS     passive use of pronoun 'se'\n",
            "<ADVS, <ADVO  adverbial argument\n",
            "<ADVL         adjunct adverbial\n",
            "<DAT          dative (indirect) object\n",
            "<FOC          focus marker (or right focus bracket)\n",
            "<OC           object complement\n",
            "<PASS         agent of passive\n",
            "<PIV          prepositional object\n",
            "<PRED         free (subject) predicative, right of main verb\n",
            "<SC           subject complement\n",
            "<SUBJ         subject\n",
            ">A            adverbial pre-adject (intensifier before adjective, adverb, pronoun or participle)\n",
            ">N            prenominal modifier\n",
            ">P            modifier of prepositional phrase (intensifier, operator or focus adverb)\n",
            ">S            modifier of clause (intensifier, operator or focus adverb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpdWBDZlWrDw"
      },
      "source": [
        "# **TextBlob**\n",
        "\n",
        "---\n",
        "\n",
        "O TextBlob já oferente uma serie de recursos de PLN, como: marcação POS-Tag, extração de frases substantivas, análise de sentimentos, classificação, tradução e outras.\n",
        "\n",
        "- Documentação oficial: https://textblob.readthedocs.io/en/dev/index.html\n",
        "- Natural Language Basics with TextBlob - Allison Parrish: http://rwet.decontextualize.com/book/textblob/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4kC31vdIlza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfdfd81-1b9b-4e41-b1d4-b0fcaa20f741"
      },
      "source": [
        "!pip install textblob"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udjWzyToWuKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716fffa0-d76b-4f44-b69c-42d921bd89bd"
      },
      "source": [
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "\n",
        "opinion = TextBlob(\"batman vs superman is a shit!\", analyzer=NaiveBayesAnalyzer())\n",
        "opinion.sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(classification='neg', p_pos=0.288629160063391, p_neg=0.7113708399366088)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuKIO5dO5Mg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac59b17-1d05-40f8-d9bd-3956d37a5ccb"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjTHSeM-SBMh"
      },
      "source": [
        "Outras funcionalidades do TextBlob, como: tradutor e pos-tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dYx4-xZWR5xs",
        "outputId": "539c75ed-64ee-40fe-ce99-861f8440ca55"
      },
      "source": [
        "'''\n",
        "texto_exemplo = \"Não sei se entendi como ler o conteúdo da view, então. \\\n",
        "Estou entendendo que a view contém um histórico das movimentações \\\n",
        "dos associados, certo?\"\n",
        "'''\n",
        "texto_exemplo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Não sei se entendi como ler o conteúdo da view, então. Estou entendendo que a view contém um histórico das movimentações dos associados, certo?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM5jokbDglMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1cdac32-48d2-437a-ba8e-e37619c41b0e"
      },
      "source": [
        "\n",
        "print(\"Frase original: \", texto_exemplo)\n",
        "\n",
        "tblob = TextBlob(texto_exemplo)\n",
        "\n",
        "##print('Idioma: ',tblob.detect_language())\n",
        "\n",
        "##en_tblob = tblob.translate(to='en')\n",
        "en_tblob = tblob.translate(from_lang='pt', to='en')\n",
        "\n",
        "print(\"Traduzido: \", en_tblob)\n",
        "\n",
        "print(\"Tags: \", en_tblob.tags)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase original:  Não sei se entendi como ler o conteúdo da view, então. Estou entendendo que a view contém um histórico das movimentações dos associados, certo?\n",
            "Traduzido:  I don't know if I understood how to read the content of the view then. I understand that View contains a history of associate movements, right?\n",
            "Tags:  [('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('know', 'VB'), ('if', 'IN'), ('I', 'PRP'), ('understood', 'VBD'), ('how', 'WRB'), ('to', 'TO'), ('read', 'VB'), ('the', 'DT'), ('content', 'NN'), ('of', 'IN'), ('the', 'DT'), ('view', 'NN'), ('then', 'RB'), ('I', 'PRP'), ('understand', 'VBP'), ('that', 'DT'), ('View', 'NNP'), ('contains', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('of', 'IN'), ('associate', 'JJ'), ('movements', 'NNS'), ('right', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJeCWBioc6Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3916ba-1a1b-4328-c986-80d93b38adae"
      },
      "source": [
        "text = \"As aulas da USP são muito chatas\"\n",
        "\n",
        "tblob = TextBlob(text)\n",
        "\n",
        "en_text = tblob.translate(from_lang='pt', to='en')\n",
        "\n",
        "en_text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"USP classes are very boring\")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_pip7sRdLV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b4c9c1-61f9-45d3-eaa4-cb05bb0abf86"
      },
      "source": [
        "en = TextBlob(en_text.string, analyzer=NaiveBayesAnalyzer())\n",
        "\n",
        "en.sentiment\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(classification='neg', p_pos=0.2782420508972421, p_neg=0.7217579491027579)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i66U-_tP3Yv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e4cd05-e96f-424f-fa90-f95cf4ff2082"
      },
      "source": [
        "\n",
        "# Exemplo com uma forma de deixar todo o texto no mesmo indioma\n",
        "en_text = \"As aulas da USP são muito chatas. My god!\"\n",
        "\n",
        "#Exemplo 1\n",
        "tblob = TextBlob(en_text)\n",
        "pt_text = tblob.translate(from_lang='en', to='pt')\n",
        "\n",
        "pt_text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"Como Aulas da USP São Muito Chatas. Meu Deus!\")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEyVtc92Vkaj"
      },
      "source": [
        "***Obs: O TextBlob para TRADUÇÕES não está funcioando a princípio, pois pelas pesquisas que eu fiz, houve alguma alteração na API do Google e a bliblioteca TextBlob não foi atualizada ainda.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9WE7opSIFp"
      },
      "source": [
        "Outro tradutor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUhLrK37I4D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08744b7-947b-4df6-e7e9-9313adb774eb"
      },
      "source": [
        "!pip install translate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting libretranslatepy==2.1.1\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from translate) (4.2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from translate) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from translate) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2.10)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hVs811vvx7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "af3dc6ca-a108-4bcc-c060-444ed66d76c8"
      },
      "source": [
        "from translate import Translator\n",
        "\n",
        "#Exemplo 2 usando outro pacote o \"translate\"\n",
        "en_text = \"As aulas da USP são muito chatas. My god!\"\n",
        "\n",
        "translator = Translator(to_lang=\"pt\")\n",
        "pt_text = translator.translate(en_text)\n",
        "\n",
        "pt_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As aulas da USP são muito chatas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW_uBucJSPmo"
      },
      "source": [
        "### Treinando um modelo do TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh1_3CoNSMV4",
        "outputId": "cd3211a5-711d-4013-a4c0-35f86377bd59"
      },
      "source": [
        "# Treinamento do Classificador TextBlob ()\n",
        "import pandas as pd\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Demostração de validação\n",
        "df_treino = pd.DataFrame({\n",
        "    'text': [\n",
        "      'Sobre MBA ? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito',\n",
        "      'O curso pode melhorar'\n",
        "    ],\n",
        "    'class': [\n",
        "        'positivo',\n",
        "        'negativo',\n",
        "        'negativo'\n",
        "    ]})\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = NaiveBayesClassifier(df_treino.values.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0faab2R6SMTg"
      },
      "source": [
        "# Demostração de validação\n",
        "df_teste = pd.DataFrame({\n",
        "    'text': [\n",
        "      'O curso pode melhorar'\n",
        "    ],\n",
        "    'class': [\n",
        "        'negativo'\n",
        "    ]})\n",
        "\n",
        "subset_teste = df_teste[['text','class']]\n",
        "tuples_teste = [tuple(x) for x in subset_teste.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUVP78mGSMOK",
        "outputId": "ccb65239-2bcb-485b-ecec-a7f4c1f015ed"
      },
      "source": [
        "accuracy = model.accuracy(df_teste[['text','class']].values.tolist())\n",
        "\n",
        "y_predito = model.classify(tuples_teste[0][0])\n",
        "y_predito\n",
        "\n",
        "print('Acurácia: {}'.format(accuracy))\n",
        "print(y_predito)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.0\n",
            "negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vlBYSFSSMLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f87696-f078-4737-bf10-cbab2f815f6a"
      },
      "source": [
        "# outra forma\n",
        "texto = 'O curso pode melhorar'\n",
        "\n",
        "blob = TextBlob(texto,classifier=model)\n",
        "\n",
        "print('Predição: {}'.format(blob.classify()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predição: negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5bpdFRLSc3n"
      },
      "source": [
        "Aplicando o modelo de classificação do TextBlob na nossa base de produtos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRpPPkhcSbmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b56311f-6130-44bb-c4ce-63a5947ea688"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# carrega os dados\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8').sample(1000)\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']\n",
        "\n",
        "# divisão das amostras em treino e teste\n",
        "df_treino, df_teste = train_test_split(\n",
        "      df, \n",
        "      test_size = 0.3, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# Preparando os dados para o modelo\n",
        "subset_treino = df_treino[['texto','categoria']]\n",
        "tuples_treino = [tuple(x) for x in subset_treino.values]\n",
        "#tuples_treino[0]\n",
        "subset_teste = df_teste[['texto','categoria']]\n",
        "tuples_teste = [tuple(x) for x in subset_teste.values]\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = NaiveBayesClassifier(tuples_treino)\n",
        "# ou\n",
        "#model = NaiveBayesClassifier(df_treino[['texto','categoria']].values.tolist())\n",
        "print(model)\n",
        "\n",
        "# validação\n",
        "accuracy = model.accuracy(tuples_teste)\n",
        "print('Precisão: {}'.format(accuracy))\n",
        "\n",
        "# classificação (predição)\n",
        "def fn_classificacao():\n",
        "  for i in range(len(tuples_teste)):\n",
        "    classification = model.classify(tuples_teste[i][0])\n",
        "    y_predito.append(classification)\n",
        "\n",
        "y_predito = []\n",
        "fn_classificacao()\n",
        "\n",
        "df_teste['categoria_predito'] = y_predito\n",
        "\n",
        "print(df_teste[['categoria','categoria_predito']].head(5))\n",
        "\n",
        "#y_predito = model.classify(df_teste[['texto','categoria']].values.tolist())\n",
        "#y_predito"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<NaiveBayesClassifier trained on 485 instances>\n",
            "Precisão: 0.7559808612440191\n",
            "      categoria categoria_predito\n",
            "2391  maquiagem         maquiagem\n",
            "363       livro         brinquedo\n",
            "967       livro             livro\n",
            "2871  maquiagem         maquiagem\n",
            "1004      livro             livro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZFcDaAUp-f2"
      },
      "source": [
        "# **SpaCy**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii4EiP-ciUGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58fbcac-13d0-4067-a5ef-fbe50877c6d4"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2022.5.18.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZERDUlN--4q"
      },
      "source": [
        "# Outros modelos do pacote SpaCy\n",
        "#!python -m spacy download en\n",
        "#!python -m spacy download en_core_web_lg\n",
        "#!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wikgr3q7zs8W"
      },
      "source": [
        "Os modelos e linguagens que o SpaCy suporta: https://spacy.io/usage/models\n",
        "\n",
        "Detalhes do modelo em português: https://spacy.io/models/pt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxv4W49BqDC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d06a09-cab4-442d-874e-77d066e25eb7"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "doc = nlp(u'Você encontrou o livro que eu te falei, Carla?')\n",
        "\n",
        "print(type(doc))\n",
        "print([token.orth_ for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.doc.Doc'>\n",
            "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', ',', 'Carla', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkxmhVTe16p4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa600ebb-276e-4a5b-e4ea-55f5554b335d"
      },
      "source": [
        "print([token.text for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', ',', 'Carla', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvXJTq8ofR3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b70117d-eb98-41fc-a7f7-fd5e3afd9c1b"
      },
      "source": [
        "type(doc[0].orth_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXLpdMNH3XxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "97a737f8-fee6-4b39-c3aa-22a62b8f102d"
      },
      "source": [
        "doc[0].orth_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Você'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kihe7mhKrZFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216f9a47-bd55-4142-d505-7e4d1c2013b1"
      },
      "source": [
        "[(token.text, token.orth_, token.pos_, token.dep_, spacy.explain(token.pos_)) for token in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Você', 'Você', 'PRON', 'nsubj', 'pronoun'),\n",
              " ('encontrou', 'encontrou', 'VERB', 'ROOT', 'verb'),\n",
              " ('o', 'o', 'DET', 'det', 'determiner'),\n",
              " ('livro', 'livro', 'NOUN', 'obj', 'noun'),\n",
              " ('que', 'que', 'PRON', 'obj', 'pronoun'),\n",
              " ('eu', 'eu', 'PRON', 'nsubj', 'pronoun'),\n",
              " ('te', 'te', 'VERB', 'obj', 'verb'),\n",
              " ('falei', 'falei', 'VERB', 'acl:relcl', 'verb'),\n",
              " (',', ',', 'PUNCT', 'punct', 'punctuation'),\n",
              " ('Carla', 'Carla', 'PROPN', 'conj', 'proper noun'),\n",
              " ('?', '?', 'PUNCT', 'punct', 'punctuation')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4IKxyc0ghgX"
      },
      "source": [
        "Uma lista completa de dependências sintáticas pode ser vista em: https://spacy.io/api/annotation#dependency-parsing \n",
        "\n",
        "Um bom material complementar para dependências sintáticas pode ser vista no [\"Stanford typed dependencies manual\"](https://nlp.stanford.edu/software/dependencies_manual.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGhkVL5b_kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01269ba-9c63-4ffb-d8b9-493bec979656"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Você encontrou o livro que eu te falei, Carla?"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX_bRMWpKE3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53e4610-2b6c-485c-ded9-cfdd3cd1c113"
      },
      "source": [
        "[token.lemma_ for token in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Você',\n",
              " 'encontrar',\n",
              " 'o',\n",
              " 'livrar',\n",
              " 'que',\n",
              " 'eu',\n",
              " 'te',\n",
              " 'falar',\n",
              " ',',\n",
              " 'Carla',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD_Mmy2YKE3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba50de89-9bc1-4caa-d280-6f9b08233338"
      },
      "source": [
        "doc = nlp(u'encontrardes, encontraram, encontrarão, encontrariam, encontrasse, encontraria')\n",
        "print([token.lemma_ for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIbo-wEj5JUn"
      },
      "source": [
        "Reconhecimento de entidades nomeadas - NER: Named-Enntity Recognition.\n",
        "\n",
        "Utilizada para reconhecer pessoas, locais, empresas, datas, numerais e outros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NPR6lntKE3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadf18a5-cc03-4b91-fe69-3c7b9a4dcc5a"
      },
      "source": [
        "doc = nlp(u'Pelé um dos melhores escritores do Brasil, \\\n",
        "foi o primeiro presidente da Academia Brasileira de Letras')\n",
        "\n",
        "print(doc.ents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Pelé, Brasil, Academia Brasileira de Letras)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9APZK79KE3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5441716a-706d-4831-cc84-ab84a3a90010"
      },
      "source": [
        "[(entity, entity.label_, spacy.explain(entity.label_)) for entity in doc.ents]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Pelé, 'PER', 'Named person or family.'),\n",
              " (Brasil, 'LOC', 'Non-GPE locations, mountain ranges, bodies of water'),\n",
              " (Academia Brasileira de Letras,\n",
              "  'ORG',\n",
              "  'Companies, agencies, institutions, etc.')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc0zcc6b_YZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075eab1d-3d57-4a40-f39b-3d9fc4f048b2"
      },
      "source": [
        "[(entity, entity.pos_) for entity in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Pelé, 'PROPN'),\n",
              " (um, 'NUM'),\n",
              " (dos, 'ADP'),\n",
              " (melhores, 'ADJ'),\n",
              " (escritores, 'NOUN'),\n",
              " (do, 'ADP'),\n",
              " (Brasil, 'PROPN'),\n",
              " (,, 'PUNCT'),\n",
              " (foi, 'VERB'),\n",
              " (o, 'DET'),\n",
              " (primeiro, 'ADJ'),\n",
              " (presidente, 'NOUN'),\n",
              " (da, 'ADP'),\n",
              " (Academia, 'PROPN'),\n",
              " (Brasileira, 'PROPN'),\n",
              " (de, 'ADP'),\n",
              " (Letras, 'PROPN')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_7c5mpia4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed078de2-baae-444b-9233-7f7853298f0d"
      },
      "source": [
        "doc8 = nlp(u'Google investirá 6 milhões de dólares')\n",
        "\n",
        "for token in doc8:\n",
        "    print(token.text, end =' | ')\n",
        "\n",
        "print('\\n----')\n",
        "\n",
        "for ent in doc8.ents:\n",
        "    print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google | investirá | 6 | milhões | de | dólares | \n",
            "----\n",
            "Google - ORG - Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzVAI0Z6KE3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f7db0f-7117-47d3-fcfb-da8a31093a93"
      },
      "source": [
        "doc4 = nlp(u'Esta é a primeira sentença. Sr. esta é a segunda sentença. Esta é a terceira. Você já entendeu né?')\n",
        "\n",
        "for sent in doc4.sents:\n",
        "    print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esta é a primeira sentença.\n",
            "Sr. esta é a segunda sentença.\n",
            "Esta é a terceira.\n",
            "Você já entendeu né?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv6ta7C_7D2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6493df-9992-4310-82e8-7d08a2417387"
      },
      "source": [
        "doc4[6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sr."
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E6jPE6yh38K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d2bf98-cdbc-4761-fbab-b37393c41203"
      },
      "source": [
        "print(doc4[6])\n",
        "print(doc4[6].is_sent_start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sr.\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPqiHvM7h8Np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e40b3a3-d10f-4042-9458-bd8e2c08e037"
      },
      "source": [
        "stop = nlp.Defaults.stop_words\n",
        "print(nlp.Defaults.stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'parte', 'pela', 'enquanto', 'estava', 'vinte', 'faz', 'final', 'onde', 'quieto', 'dão', 'cada', 'desta', 'menos', 'ambos', 'vindo', 'esteve', 'também', 'sua', 'maioria', 'porquê', 'lado', 'possível', 'algumas', 'bastante', 'grande', 'pôde', 'aos', 'porquanto', 'sempre', 'tentar', 'adeus', 'ainda', 'logo', 'vossos', 'aqueles', 'mil', 'duas', 'novos', 'custa', 'dessa', 'fim', 'estão', 'quê', 'sei', 'ademais', 'tenho', 'geral', 'meus', 'tentei', 'bom', 'aquilo', 'temos', 'seus', 'meu', 'tiveram', 'quinta', 'alguns', 'mas', 'doze', 'vezes', 'quarto', 'após', 'veja', 'posição', 'somente', 'vários', 'dizem', 'depois', 'nosso', 'sexto', 'talvez', 'até', 'minha', 'falta', 'qualquer', 'têm', 'acerca', 'aquele', 'porém', 'toda', 'dezasseis', 'ora', 'somos', 'forma', 'possivelmente', 'outras', 'das', 'catorze', 'entre', 'querem', 'novas', 'grandes', 'tempo', 'foi', 'da', 'nesta', 'relação', 'as', 'lá', 'vai', 'usar', 'bem', 'novo', 'mês', 'apenas', 'zero', 'tem', 'nova', 'tuas', 'certamente', 'nós', 'seu', 'neste', 'isso', 'lugar', 'naquela', 'pegar', 'dezassete', 'tais', 'sim', 'esses', 'tiveste', 'cinco', 'conhecido', 'questão', 'se', 'usa', 'quatro', 'aqui', 'conselho', 'favor', 'naquele', 'estiveram', 'tivemos', 'tente', 'você', 'no', 'seria', 'sete', 'inicio', 'sétima', 'muitos', 'já', 'essa', 'dois', 'às', 'tens', 'porque', 'mal', 'vêm', 'quais', 'pelo', 'pois', 'quinze', 'grupo', 'este', 'nada', 'tivestes', 'cedo', 'estar', 'aquelas', 'qual', 'não', 'daquele', 'vão', 'ela', 'meses', 'partir', 'tendes', 'obrigado', 'maior', 'ir', 'dar', 'todos', 'ligado', 'tu', 'outra', 'ou', 'tanta', 'então', 'na', 'vais', 'longe', 'segundo', 'como', 'área', 'por', 'tentaram', 'mesmo', 'teu', 'deve', 'ao', 'dezoito', 'números', 'mais', 'eventual', 'nossa', 'deste', 'sois', 'nunca', 'ontem', 'des', 'algo', 'meio', 'desde', 'nossas', 'vossa', 'fazer', 'valor', 'aquela', 'põe', 'outros', 'estive', 'nesse', 'numa', 'tipo', 'és', 'nas', 'dez', 'dentro', 'oitavo', 'que', 'vens', 'pode', 'agora', 'número', 'fazeis', 'caminho', 'tal', 'era', 'sexta', 'fui', 'demais', 'ver', 'assim', 'corrente', 'poder', 'suas', 'cujo', 'uns', 'pelos', 'fez', 'vez', 'exemplo', 'cento', 'estiveste', 'quando', 'nuns', 'aí', 'coisa', 'faço', 'teus', 'são', 'de', 'saber', 'cima', 'devem', 'num', 'com', 'próximo', 'fora', 'nos', 'vossas', 'estivemos', 'boa', 'contra', 'quieta', 'posso', 'debaixo', 'primeira', 'obrigada', 'ser', 'através', 'está', 'pouca', 'tua', 'último', 'do', 'menor', 'nem', 'isto', 'os', 'baixo', 'estivestes', 'foram', 'estás', 'todo', 'tanto', 'iniciar', 'muito', 'sou', 'ali', 'dezanove', 'onze', 'ponto', 'fazes', 'tudo', 'deverá', 'apoia', 'estou', 'só', 'vinda', 'conhecida', 'breve', 'dos', 'elas', 'comprida', 'seis', 'estado', 'em', 'apontar', 'momento', 'ele', 'lhe', 'umas', 'antes', 'um', 'eu', 'atrás', 'sétimo', 'sob', 'inclusive', 'certeza', 'tive', 'oitava', 'fomos', 'ter', 'fazem', 'segunda', 'apoio', 'nenhuma', 'foste', 'terceiro', 'uma', 'quero', 'quanto', 'sem', 'nessa', 'vocês', 'te', 'cuja', 'irá', 'terceira', 'estes', 'minhas', 'for', 'tarde', 'embora', 'diz', 'próxima', 'podia', 'três', 'pouco', 'desse', 'vos', 'poderá', 'tão', 'pontos', 'vem', 'para', 'daquela', 'esta', 'povo', 'quarta', 'comprido', 'contudo', 'nossos', 'cá', 'máximo', 'todas', 'próprio', 'portanto', 'é', 'parece', 'fará', 'quinto', 'esse', 'sistema', 'eles', 'essas', 'treze', 'local', 'nove', 'fazia', 'teve', 'nível', 'fostes', 'vosso', 'disso', 'põem', 'quer', 'primeiro', 'diante', 'à', 'perto', 'podem', 'estas', 'dá', 'além', 'estará', 'me', 'ambas', 'pelas', 'maiorias', 'oito', 'fazemos', 'sabe', 'vós', 'dizer', 'sobre', 'puderam', 'quem', 'direita'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWKYCRDojNR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805b66fd-cf53-4717-cae1-f97691626e90"
      },
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "413"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6UGby2DjU64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9922e6fe-ab96-4dcf-9c94-e06b2c84e15e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "len(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84IyYSblRj2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66f7283-0cd9-408a-b8d7-a455ab38ed7f"
      },
      "source": [
        "stops_spacy_nltk = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
        "stops_spacy_nltk\n",
        "len(stops_spacy_nltk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJtqP-KFjgem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fdd6d3-8cf8-40ac-bbe9-577f16fb0e40"
      },
      "source": [
        "#len(list(set(nlp.Defaults.stop_words) - set(stopwords)))\n",
        "list(set(nlp.Defaults.stop_words) - set(stopwords))[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parte',\n",
              " 'números',\n",
              " 'enquanto',\n",
              " 'dezoito',\n",
              " 'conhecida',\n",
              " 'novo',\n",
              " 'breve',\n",
              " 'mês',\n",
              " 'apenas',\n",
              " 'zero']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBTzb_DGVAii"
      },
      "source": [
        "#**Modelo de classificação**\n",
        "---\n",
        "\n",
        "<br>\n",
        "Vamos \"produtizar\" nosso melhor modelo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGvptdafSbj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c223a271-f035-4ea7-dc9d-0b11a83e5848"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Carrega o dataframe\n",
        "df = pd.DataFrame({\n",
        "    'text': [\n",
        "      'Sobre MBA ? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
        "    ],\n",
        "    'class': [\n",
        "        'positivo',\n",
        "        'negativo'\n",
        "    ]})\n",
        "\n",
        "# Vetoriza os documentos (cria um vetor treinado no contexto para o modelo)\n",
        "vect = TfidfVectorizer()\n",
        "vect.fit(df.text)\n",
        "tfidf_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(tfidf_vect.A, columns=vect.get_feature_names()).to_string())\n",
        "\n",
        "# Treina um modelo com os textos vetorizados\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(tfidf_vect, df['class'])\n",
        "\n",
        "# Valida as predições do modelo\n",
        "print('\\nD Tree: ', tree.score(tfidf_vect, df['class'])) # retorna a acurracy - precisão do modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         da        do        eu      fiap    gostei       mba  melhorar     muito       não      pode     sobre\n",
            "0  0.267970  0.376623  0.376623  0.267970  0.267970  0.535941  0.000000  0.267970  0.000000  0.000000  0.376623\n",
            "1  0.302531  0.000000  0.000000  0.302531  0.302531  0.302531  0.425196  0.302531  0.425196  0.425196  0.000000\n",
            "\n",
            "D Tree:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR2ko_vNVCIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3d46c4-60c9-449f-fae8-aa73e55a4fe7"
      },
      "source": [
        "# Vetoriza um novo documento\n",
        "vetor = vect.transform(['o curso pode melhorar'])\n",
        "\n",
        "# Faz a previsão com base no modelo previamente treinado\n",
        "print('D Tree: ', tree.predict(vetor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D Tree:  ['negativo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd0foInAVI4Q"
      },
      "source": [
        "Salvando nosso vetor treinado e nosso modelo de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onRgUHxVVCGf"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(vect, open('meu_vetor.pkl', 'wb'))\n",
        "pickle.dump(tree, open('minha_arvore.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3AsyvcTVCEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50aa46fa-b8a0-40af-cb2a-844938771cae"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 712\n",
            "drwxr-xr-x 1 root root   4096 Jun 11 18:49 .\n",
            "drwxr-xr-x 1 root root   4096 Jun 11 17:59 ..\n",
            "drwxr-xr-x 4 root root   4096 Jun  1 13:49 .config\n",
            "-rw-r--r-- 1 root root   1497 Jun 11 18:49 meu_vetor.pkl\n",
            "-rw-r--r-- 1 root root   1535 Jun 11 18:49 minha_arvore.pkl\n",
            "drwxr-xr-x 1 root root   4096 Jun  1 13:50 sample_data\n",
            "-rw-r--r-- 1 root root 701482 Jun 11 18:12 tagger.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCCCV1DzVCDA"
      },
      "source": [
        "import pickle\n",
        "\n",
        "bla_vetor = pickle.load(open('meu_vetor.pkl', 'rb'))\n",
        "bla_modelo = pickle.load(open('minha_arvore.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhLuIBNWVB-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a0e6c6-2015-4c49-ac9f-ed9203179e46"
      },
      "source": [
        "bla_vetor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvU1n9vfVB8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a560f3-3020-4157-a9e9-98600ec10645"
      },
      "source": [
        "bla_modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNb8e1KmVB5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af13ac56-686f-4cf2-931d-0ab4fb8f09e4"
      },
      "source": [
        "# Vetoriza um novo documento com o vetor carregado\n",
        "novo_vetor = bla_vetor.transform(['o curso pode melhorar'])\n",
        "\n",
        "print(pd.DataFrame(novo_vetor.A, columns=bla_vetor.get_feature_names()).to_string())\n",
        "\n",
        "# Faz a previsão com base no modelo carregado\n",
        "print('D Tree: ', bla_modelo.predict(novo_vetor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    da   do   eu  fiap  gostei  mba  melhorar  muito  não      pode  sobre\n",
            "0  0.0  0.0  0.0   0.0     0.0  0.0  0.707107    0.0  0.0  0.707107    0.0\n",
            "D Tree:  ['negativo']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_twlhPF7VTkd"
      },
      "source": [
        "Salvando no Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1yPJjrSbat"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# mostra a estrutura de pastas do google drive montado no colab\n",
        "!ls -la\n",
        "!ls -la /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozZhEoPWSbX8"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(tree, open('/content/gdrive/MyDrive/minha_arvore.pkl', 'wb'))\n",
        "pickle.dump(vect, open('/content/gdrive/MyDrive/meu_vetorizador.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3FxYxPaSMCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c07e2a-6d52-455b-f0bf-257fc23aa75c"
      },
      "source": [
        "!ls -la /content/gdrive/MyDrive/minha_arvore.pkl\n",
        "!ls -la /content/gdrive/MyDrive/meu_vetorizador.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1535 Jun 11 18:52 /content/gdrive/MyDrive/minha_arvore.pkl\n",
            "-rw------- 1 root root 1497 Jun 11 18:52 /content/gdrive/MyDrive/meu_vetorizador.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGS2QpmIVcUr"
      },
      "source": [
        "Reinicie o colab... <control>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd-z1RgBVZZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4f0cce-8432-4e86-c64b-df3463d381ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q90ce-pVZVg"
      },
      "source": [
        "import pickle\n",
        "\n",
        "minha_arvore = pickle.load(open('/content/gdrive/MyDrive/minha_arvore.pkl', 'rb'))\n",
        "meu_vetorizador = pickle.load(open('/content/gdrive/MyDrive/meu_vetorizador.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYGSne5hVZRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52af7a27-be34-4ea1-f7e6-ae19fff870df"
      },
      "source": [
        "# Vetoriza um novo documento com o vetor carregado\n",
        "novo_vetor = meu_vetorizador.transform(['o curso pode melhorar'])\n",
        "\n",
        "# Faz a previsão com base no modelo carregado\n",
        "print('D Tree: ', minha_arvore.predict(novo_vetor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D Tree:  ['negativo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeL9MBwPVi0r"
      },
      "source": [
        "Escorando os documentos de um novo dataframe com as predições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwDLrvb0VYx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "01bfc7a3-2417-4bd9-81ed-6fd742190875"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dataframe sem classificação\n",
        "df_novo = pd.DataFrame({\n",
        "    'texto': [\n",
        "      'Sobre MBA ? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito',\n",
        "      'O curso pode melhorar'\n",
        "    ]})\n",
        "\n",
        "df_novo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           texto\n",
              "0     Sobre MBA ? Eu gostei muito do MBA da FIAP\n",
              "1  O MBA da FIAP pode melhorar, não gostei muito\n",
              "2                          O curso pode melhorar"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4235b96-4aa2-4a92-b484-74314c1fdd5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sobre MBA ? Eu gostei muito do MBA da FIAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O curso pode melhorar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4235b96-4aa2-4a92-b484-74314c1fdd5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4235b96-4aa2-4a92-b484-74314c1fdd5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4235b96-4aa2-4a92-b484-74314c1fdd5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZGpHzLzVYvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daac0856-ae2a-48fb-adc2-d5d56a4f18fb"
      },
      "source": [
        "texto_vetorizado = meu_vetorizador.transform(df_novo.texto)\n",
        "\n",
        "print(pd.DataFrame(texto_vetorizado.A, columns=meu_vetorizador.get_feature_names()).to_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         da        do        eu      fiap    gostei       mba  melhorar     muito       não      pode     sobre\n",
            "0  0.267970  0.376623  0.376623  0.267970  0.267970  0.535941  0.000000  0.267970  0.000000  0.000000  0.376623\n",
            "1  0.302531  0.000000  0.000000  0.302531  0.302531  0.302531  0.425196  0.302531  0.425196  0.425196  0.000000\n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.707107  0.000000  0.000000  0.707107  0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAHrcXcgVm28"
      },
      "source": [
        "df_novo['class_predict'] = minha_arvore.predict(texto_vetorizado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKynjMOTVm0x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "2aa55321-5636-4c9b-d009-00032a3aad8f"
      },
      "source": [
        "df_novo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           texto class_predict\n",
              "0     Sobre MBA ? Eu gostei muito do MBA da FIAP      positivo\n",
              "1  O MBA da FIAP pode melhorar, não gostei muito      negativo\n",
              "2                          O curso pode melhorar      negativo"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75531410-979b-4141-b78f-b7ff638f6e86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>class_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sobre MBA ? Eu gostei muito do MBA da FIAP</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O curso pode melhorar</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75531410-979b-4141-b78f-b7ff638f6e86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75531410-979b-4141-b78f-b7ff638f6e86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75531410-979b-4141-b78f-b7ff638f6e86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMpK0H06Vysa"
      },
      "source": [
        "### **Exercício 1**\n",
        "\n",
        "###Que tal fazer isso com seu melhor modelo classificador de produtos?\n",
        "\n",
        "- Crie um pipeline produtivo do seu melhor modelo até aqui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAQofki-VmyD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umX6P7asHaxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32luCbaKV4ko"
      },
      "source": [
        "#**Outros modelos de classificação**\n",
        "---\n",
        "<br>\n",
        "\n",
        "###O ***Scikit-Learn*** nos permite explorar mais modelos de classificação além da Árvore de Decisão (DecisionTreeClassifier), veja:\n",
        "<br>\n",
        "\n",
        "- Regressão Logistica (LogisticRegression)\n",
        "- Random Forest (RandomForestClassifier)\n",
        "- Naive Bayes (MultinomialNB e BernoulliNB)\n",
        "\n",
        "Entre outros..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHJhQ4QwVmtD"
      },
      "source": [
        "# Modelos de Regressão\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Random Forest (baseados em Ávores de Decisões)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Naive Bayes, bastante utilizado para classificar textos baseado na frequência das palavras independnetemente do contexto (classificação de SPAM)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdsbc8EqV_OP"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/linear_model.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRMIr0ReWCIE"
      },
      "source": [
        "Exemplo com Regressão Logística:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcXVMEG_V6-t",
        "outputId": "c1043a6d-83e3-4e17-f2c9-dd8b7612e136"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# carrega os dados\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']\n",
        "\n",
        "# divisão das amostras em treino e teste\n",
        "df_treino, df_teste = train_test_split(\n",
        "      df, \n",
        "      test_size = 0.3, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "#df.shape\n",
        "#df_treino.shape\n",
        "#df_teste.shape\n",
        "\n",
        "## TREINAMENTO\n",
        "# vetorização do dataframe de treino\n",
        "vect = CountVectorizer(ngram_range=(1,1)) # vetorização por contagem de termos simples dos unigramas com stopwords\n",
        "vect.fit(df_treino.texto)\n",
        "text_vect_treino = vect.transform(df_treino.texto)\n",
        "\n",
        "# treinamento do modelo\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(text_vect_treino, df_treino.categoria)\n",
        "\n",
        "## VALIDAÇÃO\n",
        "# vetorização do dataframe de teste\n",
        "text_vect_teste = vect.transform(df_teste.texto)\n",
        "\n",
        "# escoragem da classificação na amostra de teste (textos vetorizados)\n",
        "y_predicao = model.predict(text_vect_teste)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "y_teste = df_teste.categoria\n",
        "accuracy = accuracy_score(y_predicao, y_teste) # predito x classificação original\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9805714285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5lcBFbQD4ve"
      },
      "source": [
        "### **Exercício 2**\n",
        "\n",
        "Dado o dataset de produtos [1], descubra:\n",
        "- Treine deferentes modelos de classificação do pacote scikit-learn para classificar os produtos em suas categorias.\n",
        "- Experimente a lib SpaCy para remover as stop words e reduzir as palavras ao seu lema. Veja como essas alterações impactam o desempenho do classificador.\n",
        "- Compare a performance entre eles usando a métrica de acurácia.\n",
        "- Use randon_state igual a 42 para permitir a comparação com seus colegas, separando 30% para teste.\n",
        "\n",
        "\n",
        "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY3PjYltDrbx"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayq4fTtYiq3J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ORAfF9QUMRh"
      },
      "source": [
        "# **SpaCy**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnj4fXwvURfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1290d04-2b79-479c-ca51-cb34b66a7d07"
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Ih55KpUS2u"
      },
      "source": [
        "#!python -m spacy download en\n",
        "#!python -m spacy download en_core_web_lg\n",
        "#!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IukkB7hUku9M"
      },
      "source": [
        "## Correspondência Baseada em Regras \n",
        "\n",
        "O spaCy oferece uma ferramenta de correspondência de regras chamada Matcher, que permite criar uma biblioteca de padrões de token e, em seguida, associar esses padrões a um objeto Doc para retornar uma lista de correspondências encontradas. Você pode combinar em qualquer parte do token, incluindo texto e anotações, e você pode adicionar vários padrões ao mesmo combinador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uutHbv8UkGaT"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trlgtXz5lJ6J"
      },
      "source": [
        "Aqui matcher é um objeto que é emparelhado com o objeto Vocab atual. Podemos adicionar e remover matchers nomeados específicos para o matcher, conforme necessário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiJM5rJ1loqQ"
      },
      "source": [
        "Podemos encontrar o termo \"guarda-chuva\" como uma palavra ou duas, com ou sem um hífen. Nesta seção, vamos desenvolver um matcher que encontre todos os três:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iITO-2i-lBCH"
      },
      "source": [
        "pattern1 = [{'LOWER': 'guardachuva'}]\n",
        "pattern2 = [{'LOWER': 'guarda'}, {'LOWER': 'chuva'}]\n",
        "pattern3 = [{'LOWER': 'guarda'}, {'IS_PUNCT': True}, {'LOWER': 'chuva'}]\n",
        "\n",
        "matcher.add('GuardaChuva', None, pattern1, pattern2, pattern3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5TSsvpsmDvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072a8c55-a2ba-4041-8278-b09d8e029fb2"
      },
      "source": [
        "doc = nlp('Hoje eu esqueci meu guardachuva. \\\n",
        "Vou ter que comprar um novo guarda - chuva. \\\n",
        "Quanto custa um guarda chuva?')\n",
        "\n",
        "found_matches = matcher(doc)\n",
        "print(found_matches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(12789480426693079439, 4, 5), (12789480426693079439, 12, 15), (12789480426693079439, 19, 21)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3t8-Nw1fVFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8faa81-5c84-4039-8375-7b3a3a4df40e"
      },
      "source": [
        "doc[4:5]\n",
        "doc[12:15]\n",
        "doc[19:21]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "guarda chuva"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD4o3trJmflv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0f1c69-b274-41e5-92c1-06f0840ee8a1"
      },
      "source": [
        "for match_id, start, end in found_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "    span = doc[start:end]\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12789480426693079439 GuardaChuva 4 5 guardachuva\n",
            "12789480426693079439 GuardaChuva 12 15 guarda - chuva\n",
            "12789480426693079439 GuardaChuva 19 21 guarda chuva\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts7j9EGOhK-q"
      },
      "source": [
        "É possível usar opções de POS Tag e o Lema dos termos como no exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT0aMgDWbpsT"
      },
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "pattern = [{'POS': 'VERB'}]\n",
        "\n",
        "matcher.add('Personalida', None, pattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRyd7YOgcbug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445bd67a-1dd1-4574-8df4-364858adf7b1"
      },
      "source": [
        "doc = nlp('O presidente Barak Obama visitou o Brasil')\n",
        "\n",
        "found_matches = matcher(doc)\n",
        "print(found_matches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(9998440168381091967, 4, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLD9iHbmmUN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beb0596-0d47-4a10-9b32-ff359e4fb5be"
      },
      "source": [
        "doc[4:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "visitou"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf2xl7j3TEu7"
      },
      "source": [
        "Outro exemplo combinando regras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_AJaJaTC9a"
      },
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "pattern = [{'TEXT': 'andar', 'POS': 'NOUN'}]\n",
        "\n",
        "matcher.add('Regra 1', None, pattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulaw8TyvTC7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96df14e7-3cc4-4c13-dbfa-881c18c9a8d5"
      },
      "source": [
        "doc = nlp('Vamos andar até a esquina e depois subir para o terceiro andar do prédio.')\n",
        "\n",
        "found_matches = matcher(doc)\n",
        "print(found_matches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6205818778458672271, 11, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1zGqlPTC32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eddbac3-4fca-4174-d836-579a10ed9062"
      },
      "source": [
        "[(token.text, token.orth_, token.pos_, token.dep_, spacy.explain(token.pos_)) for token in doc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Vamos', 'Vamos', 'AUX', 'aux', 'auxiliary'),\n",
              " ('andar', 'andar', 'VERB', 'ROOT', 'verb'),\n",
              " ('até', 'até', 'ADP', 'case', 'adposition'),\n",
              " ('a', 'a', 'DET', 'det', 'determiner'),\n",
              " ('esquina', 'esquina', 'NOUN', 'obl', 'noun'),\n",
              " ('e', 'e', 'CCONJ', 'cc', 'coordinating conjunction'),\n",
              " ('depois', 'depois', 'ADV', 'advmod', 'adverb'),\n",
              " ('subir', 'subir', 'VERB', 'conj', 'verb'),\n",
              " ('para', 'para', 'ADP', 'case', 'adposition'),\n",
              " ('o', 'o', 'DET', 'det', 'determiner'),\n",
              " ('terceiro', 'terceiro', 'ADJ', 'amod', 'adjective'),\n",
              " ('andar', 'andar', 'NOUN', 'obl', 'noun'),\n",
              " ('do', 'do', 'ADV', 'case', 'adverb'),\n",
              " ('prédio', 'prédio', 'NOUN', 'nmod', 'noun'),\n",
              " ('.', '.', 'PUNCT', 'punct', 'punctuation')]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2qY-3uTnFWA"
      },
      "source": [
        "Os seguintes quantificadores podem ser passados para a chave `'OP'`:\n",
        "\n",
        "<table><tr><th>OP</th><th>Descrição</th></tr>\n",
        "\n",
        "<tr ><td><span >\\!</span></td><td>Nega o padrão, exigindo que ele corresponda exatamente 0 vezes</td></tr>\n",
        "<tr ><td><span >?</span></td><td>Torna o padrão opcional, permitindo que ele corresponda 0 ou 1 vezes</td></tr>\n",
        "<tr ><td><span >\\+</span></td><td>Exige que o padrão corresponda a uma ou mais vezes</td></tr>\n",
        "<tr ><td><span >\\*</span></td><td>Permite que o padrão corresponda a zero ou mais vezes</td></tr>\n",
        "</table>\n",
        "\n",
        "**Outros atributos de token**\n",
        "\n",
        "<table><tr><th>Atributo</th><th>Descrição</th></tr>\n",
        "\n",
        "<tr ><td><span >`ORTH`</span></td><td>O texto exato do token</td></tr>\n",
        "<tr ><td><span >`LOWER`</span></td><td>O texto em caixa baixa</td></tr>\n",
        "<tr ><td><span >`LENGTH`</span></td><td>O tamanho do texto do token</td></tr>\n",
        "<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>O texto do token consiste de alfanuméricos, ASCII, digitos</td></tr>\n",
        "<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>O texto do toen esta em  lowercase, uppercase, titlecase</td></tr>\n",
        "<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token é puntuação, espaço, stop-word</td></tr>\n",
        "<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Texto do token se parece um numero, URL, email</td></tr>\n",
        "<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>O token em sua representação de POS Tag, dependência, </td></tr>\n",
        "<tr ><td><span >`ENT_TYPE`</span></td><td>O tipo de entidade do token</td></tr>\n",
        "\n",
        "</table>\n",
        "\n",
        "\n",
        "Para saber mais sobre esta função da lib SpaCy: \n",
        "\n",
        "https://spacy.io/api/matcher\n",
        "\n",
        "https://spacy.io/usage/rule-based-matching\n",
        "\n",
        "https://spacy.io/usage/linguistic-features#section-rule-based-matching"
      ]
    }
  ]
}