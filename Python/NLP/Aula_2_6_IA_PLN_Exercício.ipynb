{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghedin-alison/NLP/blob/main/Aula_2_6_IA_PLN_Exerc%C3%ADcio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2BT_ZwvhEKF"
      },
      "source": [
        "## Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbxTY0CHaaDl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "9fd5649d-ef76-4c01-c4f4-9d4bad0daef6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     nome  \\\n",
              "count                                4080   \n",
              "unique                               3696   \n",
              "top      Boneco Dragon Ball Z Son Gokou     \n",
              "freq                                   20   \n",
              "\n",
              "                                                descricao categoria  \n",
              "count                                                2916      4080  \n",
              "unique                                               2460         4  \n",
              "top     JOGO ORIGINAL. NOVO. LACRADO. PRONTA ENTREGA. ...     livro  \n",
              "freq                                                   39      1020  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa88688f-7923-4d49-8b5f-236c7412d134\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome</th>\n",
              "      <th>descricao</th>\n",
              "      <th>categoria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4080</td>\n",
              "      <td>2916</td>\n",
              "      <td>4080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3696</td>\n",
              "      <td>2460</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Boneco Dragon Ball Z Son Gokou</td>\n",
              "      <td>JOGO ORIGINAL. NOVO. LACRADO. PRONTA ENTREGA. ...</td>\n",
              "      <td>livro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa88688f-7923-4d49-8b5f-236c7412d134')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa88688f-7923-4d49-8b5f-236c7412d134 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa88688f-7923-4d49-8b5f-236c7412d134');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNYOb9Z5kJm0"
      },
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# mostrar a estrutura de pastas do google drive montado\n",
        "!ls -la\n",
        "!ls -la gdrive/MyDrive/FIAP/NLP/dados\n",
        "\n",
        "# carrega dataframe do Google Drive\n",
        "df = pd.read_csv(\"gdrive/MyDrive/FIAP/NLP/dados/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "df = pd.read_csv(\"gdrive/MyDrive/<diretorio>/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1AsI8DhJN3"
      },
      "source": [
        "## Exclua as linhas com os valores nulos e crie uma nova coluna “texto” com a junção do nome e descrição dos produtos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzdJoltLsMnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e296a1-7c48-455c-fa77-5b1a9f1636e0"
      },
      "source": [
        "df.dropna(inplace=True) # exclui registros com valores faltantes no própro objeto. inplace=False retorna uma cópia sem alterar o objeto.\n",
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2916, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5naO2LQHb8c-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "96a9cb27-d16d-40d3-e2fc-b07c95fec746"
      },
      "source": [
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao'] # cria uma nova culuna com os valores concatenados\n",
        "df.texto[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eok0vq2diIFa"
      },
      "source": [
        "## Quantos Unigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAz1ZRXwtag-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5092ffd-b220-4a8c-8809-432f0b078c86"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esse vetor resultante será salvo para utilização junto com o modelo!!!!!!!!"
      ],
      "metadata": {
        "id": "eXAzhl9GlHzU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7EsxlE8gzY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3111510-e482-4896-d86b-460b6b8d2cce"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # Converte uma coleção de documentos de texto em uma matriz de contagens de tokens\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('UNIGRAMAS com STOPWORDS', text_vect.shape[1]) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNIGRAMAS com STOPWORDS 35466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eOSRnStSE1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a97e754-5f17-448d-a55c-5eb7ddaa26e4"
      },
      "source": [
        "len(vect.get_feature_names_out())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35466"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxswZwj1sXV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bc3f99-465a-4825-ba13-39c470873da3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords  )\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNIGRAMAS sem STOPWORDS 35307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTboWmwxtiXw"
      },
      "source": [
        "## Quantos Bigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVWal6nhtlRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14606be7-a101-4d33-d236-aeba5552870c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('BIGRAMAS com STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAMAS com STOPWORDS 159553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7gDFjEYjMoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70c3367-3493-4bbd-d8d6-ca25abaeb7c6"
      },
      "source": [
        "text_vect"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2916x159553 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 456768 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InldwDGxtlsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a1656a-1b34-429b-fba0-e914ca13c973"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('BIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAMAS sem STOPWORDS 145224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O85EfGNtzhN"
      },
      "source": [
        "## Quantos Trigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM0puN6Jt67t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a9413c-423b-4ccf-d11d-2d05252d0503"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(3,3))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('TRIGRAMAS com STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRIGRAMAS com STOPWORDS 228162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDfuZ3hht7Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff832d3-3bcd-498b-bf9b-b9ec456047f7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('TRIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRIGRAMAS sem STOPWORDS 177377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hUJ2U3nj1xt"
      },
      "source": [
        "## Quantos verbos e adverbios existem na nova coluna?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWpgtWG0vKS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5451028e-ef95-42a5-aa3e-110820f9d5aa"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij4J1taKd_DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc4d9d4-e667-4810-a22f-35ec217ac99f"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize('O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'Hobbit',\n",
              " '-',\n",
              " '7ª',\n",
              " 'Ed',\n",
              " '.',\n",
              " '2013',\n",
              " 'Produto',\n",
              " 'NovoBilbo',\n",
              " 'Bolseiro',\n",
              " 'é',\n",
              " 'um',\n",
              " 'hobbit',\n",
              " 'que']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Odl4b9aiOnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed70d7d-e79a-406a-cc4d-214a9749608b"
      },
      "source": [
        "df['tokens'] = df.texto.apply(word_tokenize) # aplica a tokenização no campo texto\n",
        "\n",
        "df[[\"tokens\",\"texto\"]].head(2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...\n",
              "1       [Livro, -, It, A, Coisa, -, Stephen, King, Pro...\n",
              "2       [Box, As, Crônicas, De, Gelo, E, Fogo, Pocket,...\n",
              "3       [Box, Harry, Potter, Produto, Novo, e, Físico,...\n",
              "4       [Livro, Origem, -, Dan, Brown, Produto, NovoDe...\n",
              "                              ...                        \n",
              "4073    [Red, Dead, Redemption, Edição, Do, Ano, Goty,...\n",
              "4074    [Jogo, Gta, 5, Grand, Theft, Auto, V, Ps4, Míd...\n",
              "4075    [Zelda, :, Breath, Of, The, Wild, -, Expansion...\n",
              "4078    [Gta, San, Andreas, Hd, Remastered, Ps3, Envio...\n",
              "4079    [Mini, Game, Nova, Portátil, 10mil, Jogos, Pla...\n",
              "Name: tokens, Length: 2916, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuyoJ0Gi1bGa"
      },
      "source": [
        "'''\n",
        "pd.set_option('display.max_colwidth', -1) # habilita a descrição completa do conteúdo das colunas\n",
        "df[[\"tokens\",\"texto\"]].head(2)\n",
        "pd.reset_option('display.max_colwidth')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohNe2lI6eBWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd7d96e-6dee-49bf-ee97-e5b6d8dad1b6"
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "\n",
        "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
        "\n",
        "df.tags.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [(O, NOUN), (Hobbit, NOUN), (-, .), (7ª, NUM),...\n",
              "1    [(Livro, NOUN), (-, .), (It, PRON), (A, DET), ...\n",
              "2    [(Box, NOUN), (As, ADP), (Crônicas, NOUN), (De...\n",
              "3    [(Box, NOUN), (Harry, NOUN), (Potter, NOUN), (...\n",
              "4    [(Livro, NOUN), (Origem, NOUN), (-, .), (Dan, ...\n",
              "Name: tags, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUZnYjJ7fLUK"
      },
      "source": [
        "df.tags[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dl5TtRpfvKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2f47c1-769d-4671-c53b-f18de555b440"
      },
      "source": [
        "from collections import Counter\n",
        "counter = Counter()\n",
        "\n",
        "counter['a'] += 2\n",
        "counter\n",
        "\n",
        "counter.update('a')\n",
        "counter.update('b')\n",
        "counter"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'a': 3, 'b': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiHuebNkKoNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904942c8-7233-49a1-f53d-462de81fbbb5"
      },
      "source": [
        "tags = df.tags[1]\n",
        "print(tags)\n",
        "print(\" \")\n",
        "\n",
        "for word, tag in tags[:5]:\n",
        "  print(f\"word: {word} / tag: {tag}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Livro', 'NOUN'), ('-', '.'), ('It', 'PRON'), ('A', 'DET'), ('Coisa', 'NOUN'), ('-', '.'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('Produto', 'NOUN'), ('NovoDurante', 'NOUN'), ('as', 'ADP'), ('férias', 'ADJ'), ('escolares', 'NOUN'), ('de', 'ADP'), ('1958', 'NUM'), (',', '.'), ('em', 'X'), ('Derry', 'NOUN'), (',', '.'), ('pacata', 'NOUN'), ('cidadezinha', 'NOUN'), ('do', 'VERB'), ('Maine', 'NOUN'), (',', '.'), ('Bill', 'NOUN'), (',', '.'), ('Richie', 'NOUN'), (',', '.'), ('Stan', 'NOUN'), (',', '.'), ('Mike', 'NOUN'), (',', '.'), ('Eddie', 'NOUN'), (',', '.'), ('Ben', 'NOUN'), ('e', 'VERB'), ('Beverly', 'NOUN'), ('aprenderam', 'NOUN'), ('o', 'NOUN'), ('real', 'ADJ'), ('sentido', 'NOUN'), ('da', 'NOUN'), ('amizade', 'NOUN'), (',', '.'), ('do', 'VERB'), ('amor', 'ADV'), (',', '.'), ('da', 'NOUN'), ('confiança', 'NOUN'), ('e', 'NOUN'), ('...', '.'), ('do', 'VERB'), ('medo', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('mais', 'VERB'), ('profundo', 'ADJ'), ('e', 'NOUN'), ('tenebroso', 'NOUN'), ('medo', 'NOUN'), ('.', '.'), ('Naquele', 'NOUN'), ('verão', 'NOUN'), (',', '.'), ('eles', 'VERB'), ('enfrentaram', 'X'), ('pela', 'NOUN'), ('primeira', 'NOUN'), ('vez', 'VERB'), ('a', 'DET'), ('Coisa', 'NOUN'), (',', '.'), ('um', 'ADJ'), ('ser', 'NOUN'), ('sobrenatural', 'ADJ'), ('e', 'NOUN'), ('maligno', 'NOUN'), ('que', 'NOUN'), ('deixou', 'NOUN'), ('terríveis', 'NOUN'), ('marcas', 'NOUN'), ('de', 'ADP'), ('sangue', 'X'), ('em', 'NOUN'), ('Derry', 'NOUN'), ('.', '.'), ('Quase', 'NOUN'), ('trinta', 'ADJ'), ('anos', 'NOUN'), ('depois', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('voltam', 'NOUN'), ('a', 'DET'), ('se', 'ADJ'), ('encontrar', 'NOUN'), ('.', '.'), ('Uma', 'NOUN'), ('nova', 'ADJ'), ('onda', 'NOUN'), ('de', 'ADP'), ('terror', 'NOUN'), ('tomou', 'VERB'), ('a', 'DET'), ('pequena', 'NOUN'), ('cidade', 'NOUN'), ('.', '.'), ('Mike', 'NOUN'), ('Hanlon', 'NOUN'), (',', '.'), ('o', 'ADJ'), ('único', 'NOUN'), ('que', 'NOUN'), ('permanece', 'NOUN'), ('em', 'NOUN'), ('Derry', 'NOUN'), (',', '.'), ('dá', 'NOUN'), ('o', 'ADJ'), ('sinal', 'ADJ'), ('.', '.'), ('Precisam', 'NOUN'), ('unir', 'ADJ'), ('forças', 'NOUN'), ('novamente', 'NOUN'), ('.', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), ('volta', 'NOUN'), ('a', 'DET'), ('atacar', 'NOUN'), ('e', 'NOUN'), ('eles', 'NOUN'), ('devem', 'VERB'), ('cumprir', 'VERB'), ('a', 'DET'), ('promessa', 'NOUN'), ('selada', 'NOUN'), ('com', 'NOUN'), ('sangue', 'NOUN'), ('que', 'NOUN'), ('fizeram', 'NOUN'), ('quando', 'NOUN'), ('crianças', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('têm', 'VERB'), ('a', 'DET'), ('chave', 'NOUN'), ('do', 'NOUN'), ('enigma', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('sabem', 'X'), ('o', 'ADJ'), ('que', 'NOUN'), ('se', 'NOUN'), ('esconde', 'NOUN'), ('nas', 'NOUN'), ('entranhas', 'X'), ('de', 'X'), ('Derry', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('tempo', 'ADJ'), ('é', 'NOUN'), ('curto', 'NOUN'), (',', '.'), ('mas', 'X'), ('somente', 'NOUN'), ('eles', 'NOUN'), ('podem', 'VERB'), ('vencer', 'ADP'), ('a', 'DET'), ('Coisa', 'NOUN'), ('.', '.'), ('Em', 'NOUN'), ('``', '.'), ('It', 'PRON'), ('-', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), (\"''\", '.'), (',', '.'), ('clássico', 'X'), ('de', 'X'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('em', 'NOUN'), ('nova', 'NOUN'), ('edição', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('irão', 'NOUN'), ('até', 'NOUN'), ('o', 'NOUN'), ('fim', 'NOUN'), (',', '.'), ('mesmo', 'NOUN'), ('que', 'NOUN'), ('isso', 'NOUN'), ('signifique', 'NOUN'), ('ultrapassar', 'ADJ'), ('os', 'ADJ'), ('próprios', 'NOUN'), ('limites.CaracterísticasAutor', 'NOUN'), (':', '.'), ('King', 'NOUN'), (',', '.'), ('StephenPeso', 'NOUN'), (':', '.'), ('1.44I.S.B.N', 'NUM'), ('.', '.'), (':', '.'), ('9788560280940Altura', 'NUM'), (':', '.'), ('23.000000Largura', 'NUM'), (':', '.'), ('15.000000Profundidade', 'NUM'), (':', '.'), ('5.300000Idioma', 'NUM'), (':', '.'), ('PortuguêsAcabamento', 'NOUN'), (':', '.'), ('0Tradutor', 'NUM'), (':', '.'), ('Winarski', 'NOUN'), (',', '.'), ('RegianeNúmero', 'NOUN'), ('da', 'VERB'), ('edição', 'NOUN'), (':', '.'), ('0País', 'NUM'), ('de', 'ADP'), ('Origem', 'NOUN'), (':', '.'), ('BrasilSegmento', 'NOUN'), (':', '.'), ('Ficção', 'NOUN'), ('-', '.'), ('Histórias', 'NOUN'), ('inquietantes', 'VERB'), ('-', '.'), ('Terror', 'NOUN')]\n",
            " \n",
            "word: Livro / tag: NOUN\n",
            "word: - / tag: .\n",
            "word: It / tag: PRON\n",
            "word: A / tag: DET\n",
            "word: Coisa / tag: NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xzkR1zz3nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cc27a1-fd49-4e82-d3f0-b74293f2b00e"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "for tags in df.tags:\n",
        "  for word, tag in tags:\n",
        "    counter[tag] += 1\n",
        "\n",
        "print(f\"Verbos: {counter.get('VERB')}\")\n",
        "print(f\"Adjetivos: {counter.get('ADJ')}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbos: 41954\n",
            "Adjetivos: 50845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLvw-MU-hSv4"
      },
      "source": [
        "'''\n",
        "# para quem quiser entender como funciona a lógica, segue a mesma lógica usando print para mapear os passos\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "for tags in df.tags:\n",
        "  print(\"tags: \", tags)\n",
        "  for word, tag in tags:\n",
        "    counter[tag] += 1\n",
        "    print(\"word: \", word, \" tag: \", tag)\n",
        "\n",
        "print('Verbos', counter.get('VERB'))\n",
        "print('Adjetivos', counter.get('ADJ'))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kuPtf4ME7ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6415758-6d5a-4736-f7dc-373fffb517ef"
      },
      "source": [
        "counter.get('NOUN') # SUBSTANTIVO"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360792"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-w3pk50Ogl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bbaad0-9656-4a72-f5d8-c1fb961b647d"
      },
      "source": [
        "counter"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOUN': 360792,\n",
              "         '.': 88831,\n",
              "         'NUM': 24093,\n",
              "         'ADJ': 50845,\n",
              "         'VERB': 41954,\n",
              "         'X': 39028,\n",
              "         'ADP': 18202,\n",
              "         'DET': 15425,\n",
              "         'PRON': 282,\n",
              "         'ADV': 3653,\n",
              "         'CONJ': 1203,\n",
              "         'PRT': 1821})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh60rZ8NIijA"
      },
      "source": [
        "De/Para do POS Tag com o tagset='universal':\n",
        "\n",
        "- NOUN (nouns / substantivos)\n",
        "- VERB (verbs / verbos)\n",
        "- ADJ (adjectives / adjetivos)\n",
        "- ADV (adverbs / advérbios)\n",
        "- PRON (pronouns / pronomes)\n",
        "- DET (determiners and articles / determinantes e artigos)\n",
        "- ADP (prepositions and postpositions / preposições e postposições)\n",
        "- NUM (numerals / numerais)\n",
        "- CONJ (conjunctions / conjunções)\n",
        "- PRT (particles / partículas)\n",
        "- . (punctuation marks / sinais de pontuação)\n",
        "- X (a catch-all for other categories such as abbreviations or foreign words / um exemplo geral para outras categorias, como abreviações ou palavras estrangeiras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRICVTAt5F56"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVDjrt-eT4MV"
      },
      "source": [
        "## Aplicar Stemmer em uma frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqSkCwdUXbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad4d293-efbc-41d9-a3a2-51646763d578"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.info()\n",
        "df.dropna(inplace=True) # exclui registros com valores faltantes no própro objeto. inplace=False retorna uma cópia sem alterar o objeto.\n",
        "df.info()\n",
        "\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao'] # cria uma nova culuna com os valores concatenados\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "df['tokens'] = df.texto.apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4080 entries, 0 to 4079\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   nome       4080 non-null   object\n",
            " 1   descricao  2916 non-null   object\n",
            " 2   categoria  4080 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 95.8+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2916 entries, 0 to 4079\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   nome       2916 non-null   object\n",
            " 1   descricao  2916 non-null   object\n",
            " 2   categoria  2916 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 91.1+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJ-oLU9T3jT"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "tokens = df.tokens[0]\n",
        "\n",
        "ps = PorterStemmer()\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "for tok in tokens:\n",
        "  print('PorterStemmer: %s \\t\\t RSLPStemmer: %s' % (ps.stem(tok), rslp.stem(tok)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTMo3h0oFA7"
      },
      "source": [
        "## Quantos unigramas existem após aplicar Stemmer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlUI2NgDhufq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09e365f-0212-411a-afcb-fe485db86950"
      },
      "source": [
        "', '.join(['Anderson', 'Dourado'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Anderson, Dourado'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_3LR9sO0hRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa341a38-c5b6-4537-e2b6-eeb23fecd67a"
      },
      "source": [
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "def stem_pandas(line):\n",
        "  return ' '.join([rslp.stem(token) for token in line])\n",
        "\n",
        "df['stemmer'] = df.tokens.apply(stem_pandas)\n",
        "\n",
        "df.stemmer.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    o hobbit - 7ª ed . 2013 produt novobilb bols é...\n",
              "1    livr - it a cois - stephen king produt novodur...\n",
              "2    box as crôn de gel e fog pocket 5 livr produt ...\n",
              "3    box harry pott produt nov e físic a séri harry...\n",
              "4    livr orig - dan brown produt novod ond vi ? pa...\n",
              "Name: stemmer, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFiA2cAORmpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27e295b-7fd3-4674-e684-a60571f83680"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "vect.fit(df.stemmer)\n",
        "\n",
        "text_vect = vect.transform(df.stemmer)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNIGRAMAS sem STOPWORDS 26466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMtdbotJZxob"
      },
      "source": [
        "Comparando com o primeiro exercício => UNIGRAMAS sem STOPWORDS 35310"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QGwgdjvSW7L"
      },
      "source": [
        "NLTK = Natural Language Tool Kit\n",
        "\n",
        "RSLP = Removedor de Sulfixos da Língua Portuguesa\n"
      ]
    }
  ]
}